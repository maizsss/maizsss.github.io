{"meta":{"title":"maizsss blog","subtitle":null,"description":null,"author":"maizsss","url":"http://maizsss.github.io"},"pages":[{"title":"tags","date":"2017-10-28T07:46:22.000Z","updated":"2017-10-28T07:46:22.284Z","comments":true,"path":"tags/index.html","permalink":"http://maizsss.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-10-28T07:46:47.000Z","updated":"2017-10-28T07:46:47.151Z","comments":true,"path":"categories/index.html","permalink":"http://maizsss.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"快应用最草根指南","slug":"快应用最草根指南","date":"2018-04-10T10:13:35.000Z","updated":"2018-04-10T10:14:29.264Z","comments":true,"path":"2018/04/10/快应用最草根指南/","link":"","permalink":"http://maizsss.github.io/2018/04/10/快应用最草根指南/","excerpt":"","text":"此文档目的在于：看完后能够对快应用从生态到开发有个概念性的理解，能够清晰开发思路上的调整、工具的准备、技术栈构成。 读者能在阅读完后，结合官方文档、项目例子通过实践就可以掌握快应用的开发。 不提供”从零到XX”此类路线型的教程，不提供文档已有说明的代码使用教程。 简介 安卓十大主流厂商（小米、华为、oppo、魅族…）联合 基于手机硬件平台（系统）提供统一的、标准的接入方式、运行环境。 无需安装，秒开，具有与原生一样的应用体验，能够调用大多数系统功能、服务。 使用前端技术栈开发，基本可以（一些问题的解决思路还是要请教安卓哥）在没有安卓开发经验下面进行快应用开发。 官方文档。以推广的最初阶段而言，文档做得算是用心。大部分能描述得清楚，小部分需要很细心才能“发掘”得出来。 开发体验起步 首先开发者要具备npm相关的知识或经验。快应用整套开发环境建立在npm生态之上，类比于前端技术栈中的“vue全家桶”的开发模式。 环境搭建直接参考文档，然后阅读快速入门章节尝试运行一个demo项目。 编辑器使用vscode最佳，但原则上只要是个能写代码的都可以，.ux后缀的组件文件与html格式关联后可以高亮显示。 坑点1：请确认系统升至最新；调试器、平台预览版安装后如果还不能正常调试，请重新安装一遍 = =。。。 坑点2：如果遇到npm run server出现报错，就在项目根路径下执行hap update后重新npm install。 坑点3：nodejs版本请保证在7.6以上，别用8.0.*的版本。 调试 在安卓上的调试器，可以唤起PC机上的chrome调试。方式是点击调试器上的“开始调试”。 chrome调试界面可以看到当前页面的UI截屏（好low）； 样式、页面结构的功能很不完善； 网络请求栏，使用方法如常。 console栏。需要在项目的manifest.json文件设置log级别 123456&#123; &quot;config&quot;: &#123; //有debug、log、info、warn、error五个级别。假如设为log，那么console.debug的信息就不会被打印出来。 &quot;logLevel&quot;: &quot;debug&quot; &#125;&#125; 坑点1：执行npm run watch后，原则上会自动监测文件变动、打包、刷新，但偶现无反应状况，需要在调试器再次点击“在线更新”。 坑点2：在更新图片资源、更改manifest.json配置后，需要重新执行npm run watch 才能生效。 开发模式 先了解原理 1ux/js/css/less/img/json......==webpack==&gt; jsbundle（描述样式、结构、逻辑）、img ==webpack==&gt; rpk(jsbundle被gzip压缩后的文件) ==安卓快应用解析==&gt;调用原生功能 以.ux为后缀的单文件组件开发模式。一个.ux文件为一个组件。路由级（页面）组件、纯逻辑组件、纯结构组件、可复用UI组件。顶级入口文件为app.ux。 123456789&lt;template&gt;结构&lt;/template&gt;&lt;script&gt;逻辑&lt;/script&gt;&lt;style&gt;样式&lt;/style&gt; 在manifest.json描述整个应用的路由关系、调用功能的声明、应用信息等等。。。一定要细看！ js：可以用es6语法（babel转化），async/await。全功能的js，但要注意全局对象是global而非window，而且global的的使用场景有限。 样式：可以使用less（其实直接写css也没有不适感），布局上面只支持flex布局。大体上与web开发的css书写形式上相似，但并不等同于css，只支持有限的属性，渲染机制也（估计）不一样。 结构：与web开发不同，快应用的标签有不同的嵌套关系、支持的样式、事件，这些在文档都有描述。 提示：快应用不提供“浮动”、“绝对定位”、“块级、行内元素”这类概念的特性，降低了灵活性。但是提供各种功能性容器如：stack（层叠）、list、tabs、swiper。思路上面需要转变一些。 总结： 总体开发类似基于webpack的web单页应用开发，但某些特性上又有所区别，不适合照搬经验。 高级特性接口 路由、弹窗、分享、支付、二维码。。。。。。拥有很多系统级别的功能，支持范围、性能都大幅度领先web应用。 需要在manifest.json文件先做接口声明 1234&quot;features&quot;: [ &#123; &quot;name&quot;: &quot;system.prompt&quot; &#125;, &#123; &quot;name&quot;: &quot;system.router&quot; &#125;] 调用方式大多数走回调函数风格(但有方式改造成async函数同步调用) 123456789pkg.hasInstalled(&#123; package: &apos;com.hap.app&apos;, success: function(data) &#123; console.log(&quot;handling success: &quot; + data.result); &#125;, fail: function(data, code) &#123; console.log(&quot;handling fail, code=&quot; + code); &#125;&#125;) 调起支付宝支付 12345678910alipay.pay(&#123; orderInfo: 字符串形式的支付参数, callback:function(ret)&#123; if (ret.resultStatus === &apos;9000&apos;) &#123; // 支付成功 &#125; else &#123; // 支付失败 &#125; &#125;&#125;) 调起微信支付（黑科技：router.push能打开deeplink！） 123router.push(&#123; uri: &apos;weixin://wap/pay?支付参数&apos;&#125;) 组件通信 https://doc.quickapp.cn/tutorial/framework/parent-child-component-communication.html?h=%E7%BB%84%E4%BB%B6%E9%80%9A%E4%BF%A1优化技巧 https://doc.quickapp.cn/tutorial/framework/optimization-skills.html?h=%E4%BC%98%E5%8C%96 建议 遇到问题后多去官方论坛逛逛，相当于github的issue区。但没有搜索功能很糟糕。 文档先细看以上提到过的，其他的文档内容可以通过文档的搜索功能检索出来。 文档里多数只列出功能的使用说明，而使用例子偏少，可以下载此官方项目参考代码例子。","categories":[],"tags":[]},{"title":"koa最草根指南","slug":"koa最草根指南","date":"2018-04-10T10:11:43.000Z","updated":"2018-04-10T10:12:11.360Z","comments":true,"path":"2018/04/10/koa最草根指南/","link":"","permalink":"http://maizsss.github.io/2018/04/10/koa最草根指南/","excerpt":"","text":"koa是啥 koa——基于Node.js平台的下一代web开发框架。koa 是由 Express 原班人马打造的，致力于成为一个更小、更富有表现力、更健壮的 Web 框架。 使用 koa 编写 web 应用，通过组合不同的 generator，可以免除重复繁琐的回调函数嵌套， 并极大地提升错误处理的效率。koa 不在内核方法中绑定任何中间件， 它仅仅提供了一个轻量优雅的函数库，使得编写 Web 应用变得得心应手。 以上，是koa官方文档的简介。 区别于express，koa不提供任何中间件，只提供中间机制。 koa目前已经发展到v2.5.0版本，要求nodejs在v7.6.0以上，对比koa1版本，全面支持es6语法，async函数。 koa的实际使用方式 通过koa启动一个web服务 12345678910const Koa = require(&apos;koa&apos;);const app = new Koa();app.use(async ctx =&gt; &#123; ctx.body = &apos;hello&apos;;&#125;);app.listen(3000, () =&gt; &#123; console.log(&apos; koa server start!&apos;);&#125;); 使用中间件 123app.use(ctx =&gt; &#123; ctx.body = &apos;hello&apos;;&#125;); 使用第三方中间件（路由） 12345678910111213141516171819// 使用koa-router中间件const Koa = require(&apos;koa&apos;);const Router = require(&apos;koa-router&apos;);const app = new Koa();const router = new Router();router.get(&apos;/api&apos;, (ctx, next) =&gt; &#123; console.log(`$&#123;ctx.method&#125; $&#123;ctx.url&#125;`); console.log(ctx.router); ctx.body = `$&#123;ctx.method&#125; $&#123;ctx.url&#125;`;&#125;);app .use(router.routes()) .use(router.allowedMethods());app.listen(3000, () =&gt; &#123; console.log(&apos; koa server start!&apos;);&#125;); 在一个实际项目中的koa 1直接看项目啊。。。 koa的中间件（核心） 什么是中间件 字面意思，就是在程序中间处理各种逻辑的套件（函数）。 koa-router用于处理http请求的路由逻辑，被封装成第三方中间件的形式提供出来便于开发。 理解了koa的中间件机制，等于已经掌握了koa。 koa-compose 核心代码只有10行（真·核心）左右。在不支持async函数时，用Generator函数实现，支持async后改为Promise实现。 middleware是一个数组，里面所有元素都是函数。compose函数就是将middleware数组转化为函数套函数的调用形式。1[g1, g2, g3] =&gt; g1(g2(g3())) 中间件的执行顺序 code 12345678910111213141516171819// fn1app.use((ctx, next) =&gt; &#123; console.log(1); next(); console.log(4); &#125;);// fn2app.use((ctx, next) =&gt; &#123; console.log(2); next(); console.log(5);&#125;);// fn3app.use((ctx, next) =&gt; &#123; console.log(3); next(); console.log(6);&#125;); compose展开,伪代码 12345678910111213Promise.resolve(async (context, fn2) =&gt; &#123; console.log(1); await Promise.resolve(async (context, fn3) =&gt; &#123; console.log(2); await Promise(async (context) =&gt; &#123; console.log(3); // next(); 没有下一个中间件，return Promise.resolve() console.log(6); &#125;()); console.log(5); &#125;) console.log(4);&#125;()); image 如何捕获中间件的错误 code 1234567891011121314151617app.use((ctx, next) =&gt; &#123; console.log(1); next(); console.log(4); &#125;);app.use((ctx, next) =&gt; &#123; console.log(2); next(); console.log(5);&#125;);app.use((ctx, next) =&gt; &#123; console.log(3); aaa //错误：aaa未定义 next(); console.log(6);&#125;); 中间件内部的错误，只会中断本函数的运行，不会中断整个中间件流程的运行。 监听error事件 123app.on(&apos;error&apos;, (err, ctx) =&gt; &#123; console.error(&apos;server error&apos;, err, ctx)&#125;); 在外层中间件捕获内层的错误 12345678910111213141516171819202122app.use(async (ctx, next) =&gt; &#123; console.log(1); try &#123; await next(); &#125; catch (error) &#123; console.log(error); &#125; console.log(4); &#125;);app.use(async (ctx, next) =&gt; &#123; console.log(2); await next(); console.log(5);&#125;);app.use(async (ctx, next) =&gt; &#123; console.log(3); aaa await next(); console.log(6);&#125;); 程序解耦（为什么要用koa） 不同业务逻辑之间的隔离 公共处理层与业务逻辑之间的隔离 提供第三方统一的接入规则，方便软件生态扩大（类比一下jq插件） 如工厂流水线一样顺滑流畅的程序 koa的功能构成 app应用程序 是一个对象 包含listen、callback、use等方法 包含一组中间件，context、request、response属性 ctx上下文 是一个对象 包含request、response 包含一些公共方法 包含一些被中间件加工过后的属性 每个请求都会创建一个ctx，贯通整个请求的逻辑 req请求 包含请求信息，方法 res响应 包含响应信息，方法 扩展 koa与egg.js/thinkjs的关系 eggjs包含koa 基于koa的程序组织风格，约定了一套开发规范 目录结构、运行、配置、路由、任务、单元测试、日志、插件等。。。 增加了一些服务端分层设计的概念，Controller、Service 其实就是提供一整套开箱即用的架构代码。是大厂的脚手架搭建、开发习惯的沉淀。 常用的koa中间件 路由：koa-router body参数解析：koa-body cors跨域允许：koa2-cors session：koa-session … 如何学习koa 看官方文档 看项目，写项目 了解原理、思路：搜索引擎 进阶：参考优秀的上层框架的程序架构（如上面说到的eggjs）","categories":[],"tags":[]},{"title":"在linux环境部署nodejs项目","slug":"在linux环境部署nodejs项目","date":"2018-03-07T12:44:34.000Z","updated":"2018-03-07T12:50:31.889Z","comments":true,"path":"2018/03/07/在linux环境部署nodejs项目/","link":"","permalink":"http://maizsss.github.io/2018/03/07/在linux环境部署nodejs项目/","excerpt":"","text":"背景：当你做了一个nodejs+mongodb的项目，然后拿到了linux云主机的ip与root密码，接着要如何完成一系列的部署工作。 linux用户权限 因为root账户具有系统最高权限，如果进行了误操作或者泄露了，后果会很严重。所以一般会根据不同的操作内容建立多个非root账户，分配不同的权限。 linux的权限系统还有文件权限、用户组、提权这样的概念，理解了linux的权限系统可以更自如地进行操作和定位问题，具体可以参考文章来了解： https://www.cnblogs.com/duhuo/p/5892513.html 系统构成 简单描绘一个基本的系统架构 image 软件环境准备安装nodejs 使用nvm管理nodejs版本。nvm方便在同一台机器安装不同版本nodejs，而且可以在不同版本之间进行切换。 12wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.1/install.sh | bashsource ~/.bashrc 安装node 8.9.0 1nvm install v8.9.0 安装git 使用编译安装方式，可以安装较新版本的git 安装依赖的包1yum -y install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker 下载git源码并解压 123wget https://github.com/git/git/archive/v2.3.0.zipunzip v2.3.0.zipcd git-2.3.0 编译安装 12make prefix=/usr/local/git allmake prefix=/usr/local/git install 配置环境变量 1234567// 查看git路径whereis gitvim ~/.bashrc// 在文件的最后一行，添加下面的内容，然后保存退出。export PATH=/usr/local/git/bin:$PATH// 使配置即时生效source ~/.bashrc 设置sshkey12345678// 在linux服务端生成sshkeyssh-keygen -t rsa -C &quot;你的账号&quot;// 生成过程按回车，以默认值即可// 最终生成在~/.ssh/id_rsa(私钥) ~/.ssh/id_rsa.pub(公钥)// 复制公钥的值cat ~/.ssh/id_rsa.pub// 在gitlab部署密钥处，添加新的公钥。// 以ssh方式拉取项目：git clone git@XXXXX 安装mongodb https://maizsss.github.io/2018/01/07/mongodb%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Nginx安装12345// 搜索，yum源没有nginx源yum search nginx// 添加CentOS 7 Nginx yum资源库sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpmsudo yum install -y nginx 基本操作 安装：yum install nginx 启动：service nginx start 停止：service nginx stop 重载：service nginx reload(无缝重载) 先杀死再启动：service nginx restart虚拟主机 配置： 123456789vim /etc/nginx/conf.d/&#123;配置名&#125;.confserver &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm;&#125; 伪静态 1234567891011server &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; rewrite ^(.*)\\.htmp$ /index.html; &#125;&#125; 日志（搜索nignx log_format学习日志配置） 1234vim /etc/nginx/nginx.conflog_format &#123;日志格式名&#125; &#123;格式&#125;access_log &#123;日志路径&#125; &#123;日志格式名&#125;; 反向代理（用户请求到A机器的nginx，nginx再请求B、C机器服务，再返回给用户） 负载均衡（N台机器同时接受请求） 123456789101112131415161718upstream &#123;服务名称&#125; &#123; server &#123;ip&#125;:&#123;port&#125; weight=5; // 服务1 server &#123;ip&#125;:&#123;port&#125; weight=1; //服务2 // weight设置权重&#125;server &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; proxy_set_header Host &#123;域名&#125;; proxy_pass http://&#123;服务名&#125;; &#125;&#125; 调试 1234567891011121314151617181920upstream &#123;服务名称&#125; &#123; server &#123;ip&#125;:&#123;port&#125; weight=5; // 服务1 server &#123;ip&#125;:&#123;port&#125; weight=1; //服务2 // weight设置权重&#125;server &#123; listen 80; listen 9999; add_header Content-Type &quot;text/plain chatset=utf-8&quot;; //设置header return 200 &quot;$http_host&quot;; // 直接返回给浏览器 server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; proxy_set_header Host &#123;域名&#125;; proxy_pass http://&#123;服务名&#125;; &#125;&#125; PM2：nodejs的守护进程工具 安装,pm2是npm包，可以直接用npm全局安装。 1npm i pm2 -g 启动项目 123pm2 start app.js// 查看参数说明pm2 help 以配置文件方式启动 1pm2 start ecosystem.config.js --env production 项目部署 linux环境安装软件的工作一般是运维人员处理好，而针对单个项目的部署才是开发者需要做的。 在git项目开启ssh秘钥 以gitlab为例，如果之前已经添加过服务器的密钥，那只需要在项目的“设置”下拉菜单中，进入“部署密钥”，然后在里面找到需要部署项目的服务器的密钥，点击“启用”就能以ssh方式拉取项目。运行nodejs实例 主流做法是用pm2启动：参考上一节pm2的说明。 用nohub启动:nohup是linux环境的软件，能让进程在后台运行。 1nohup node app.js &amp; 用forever启动：具体参考（https://github.com/foreverjs/forever） 做nginx配置 nginx的说明参考上一节，或：http://www.nginx.cn/doc/ nginx本身是一个性能优秀的web服务器，用于代理静态资源是很方便的。对于nodejs服务，能解决前后端分离的跨域问题，也能实现负载均衡。防火墙通行端口 假如nginx配置了虚拟主机占用8000端口，然后在本机curl http://localhost:8000是有响应的，但在其他机器上面访问却无响应。这时候可能是因为服务器开了防火墙而8000端口没被放行。 添加端口1234// 永久添加端口firewall-cmd --permanent --zone=public --add-port=8000/tcp// reload配置firewall-cmd --reload","categories":[],"tags":[]},{"title":"mongodb学习笔记","slug":"mongodb学习笔记","date":"2018-01-07T10:31:29.000Z","updated":"2018-01-29T06:41:18.885Z","comments":true,"path":"2018/01/07/mongodb学习笔记/","link":"","permalink":"http://maizsss.github.io/2018/01/07/mongodb学习笔记/","excerpt":"","text":"安装下载1wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.4.0.tgz 解压安装配置1234567891011121314151617181920212223242526272829303132333435/** 解压 **/tar zxvf mongodb-linux-x86_64-3.4.0.tgz/** 重命名 **/mv mongodb-linux-x86_64-3.4.0.tgz mongodb/** 进入mongodb目录 **/cd mongodb/** 创建db和日志目录 **/mkdir /opt/mongodb/data mkdir /opt/mongodb/data/dbmkdir /opt/mongodb/data/logs/** logs目录下创建mongodb.log文件 **/touch mongodb.log/** 在mongodb/data目中创建mongodb.conf **/cd datavi mongodb.conf/** 加入相关配置 **/#端口号port = 27017 #数据目录dbpath = /opt/mongodb/data/db#日志目录logpath = /opt/mongodb/data/logs/mongodb.log#设置后台运行fork = true#日志输出方式logappend = true#开启认证#auth = true/** esc :wq 保存退出 **/ 运行1/opt/mongodb/bin/mongod --config /opt/mongodb/data/mongodb.conf 用户权限 教程： http://blog.csdn.net/dbabruce/article/details/50963956 创建用户 123456use admindb.createUser(&#123; user:&apos;&#123;用户名&#125;&apos;, pwd:&apos;&#123;用户密码&#125;&apos;, roles:[&#123; &quot;role&quot; : &quot;&#123;角色&#125;&quot;, &quot;db&quot; : &quot;&#123;库名&#125;&quot; &#125;]&#125;); 内置角色 123456789101112131415161718192021222324252627282930数据库用户类：read 非系统集合有查询权限readWrite 非系统集合有查询和修改权限数据库管理类：dbAdmin 数据库管理相关，比如索引管理，schema管理，统计收集等，不包括用户和角色管理dbOwner 提供数据库管理，读写权限，用户和角色管理相关功能userAdmin 提供数据库用户和角色管理相关功能集群管理类：clusterAdmin 提供最大集群管理权限clusterManager 提供集群管理和监控权限clusterMonitor 提供对监控工具只读权限hostManager 提供监控和管理severs权限备份和恢复类：backup 提供数据库备份权限restore 提供数据恢复权限All-Database类：readAnyDatabase 提供读取所有数据库的权限除了local和config数据库之外readWriteAnyDatabase 和readAnyDatabase一样，除了增加了写权限userAdminAnyDatabase 管理用户所有数据库权限，单个数据库权限和userAdmin角色一样dbAdminAnyDatabase 提供所有用户管理权限，除了local,config超级用户类：root 数据库所有权限内部角色：__system 提供数据库所有对象任何操作的权限，不能分配给用户，非常危险 命令 教程： https://www.cnblogs.com/PheonixHkbxoic/p/5665499.html 关闭 123456789// 开启mongo命令行./bin/mongo// 使用admin权限use admin// 关闭服务,不kill进程db.shutdownServer()// 关闭进程mongod --shutdown --dbpath /opt/mongodb/data/db db的帮助 1234567891011121314151617181920212223242526272829303132db.changeUserPassword(username,password); 修改用户密码 db.auth(usrename,password) 设置数据库连接验证 db.cloneDataBase(fromhost) 从目标服务器克隆一个数据库 db.commandHelp(name) returns the help for the command db.copyDatabase(fromdb,todb,fromhost) 复制数据库fromdb---源数据库名称，todb---目标数据库名称，fromhost---源数据库服务器地址 db.createCollection(name,&#123;size:3333,capped:333,max:88888&#125;) 创建一个数据集，相当于一个表 db.currentOp() 取消当前库的当前操作 db.dropDataBase() 删除当前数据库 db.eval(func,args) run code server-side db.getCollection(cname) 取得一个数据集合，同用法：db[&apos;cname&apos;] or db.getCollenctionNames() 取得所有数据集合的名称列表 db.getLastError() 返回最后一个错误的提示消息 db.getLastErrorObj() 返回最后一个错误的对象 db.getMongo() 取得当前服务器的连接对象get the server db.getMondo().setSlaveOk() allow this connection to read from then nonmaster membr of a replica pair db.getName() 返回当操作数据库的名称 db.getPrevError() 返回上一个错误对象 db.getProfilingLevel() 获取profile level db.getReplicationInfo() 获得重复的数据 db.getSisterDB(name) get the db at the same server as this onew db.killOp() 停止（杀死）在当前库的当前操作 db.printCollectionStats() 返回当前库的数据集状态 db.printReplicationInfo() 打印主数据库的复制状态信息 db.printSlaveReplicationInfo() 打印从数据库的复制状态信息 db.printShardingStatus() 返回当前数据库是否为共享数据库 db.removeUser(username) 删除用户 db.repairDatabase() 修复当前数据库 db.resetError() db.runCommand(cmdObj) run a database command. if cmdObj is a string, turns it into &#123;cmdObj:1&#125; db.setProfilingLevel(level) 设置profile level 0=off,1=slow,2=all db.shutdownServer() 关闭当前服务程序 db.version() 返回当前程序的版本信息 表的帮助，格式，db.表名.help() 123456789101112131415161718192021db.test.find(&#123;id:10&#125;) 返回test数据集ID=10的数据集 db.test.find(&#123;id:10&#125;).count() 返回test数据集ID=10的数据总数 db.test.find(&#123;id:10&#125;).limit(2) 返回test数据集ID=10的数据集从第二条开始的数据集 db.test.find(&#123;id:10&#125;).skip(8) 返回test数据集ID=10的数据集从0到第八条的数据集 db.test.find(&#123;id:10&#125;).limit(2).skip(8) 返回test数据集ID=1=的数据集从第二条到第八条的数据 db.test.find(&#123;id:10&#125;).sort() 返回test数据集ID=10的排序数据集 db.test.findOne([query]) 返回符合条件的一条数据 db.test.getDB() 返回此数据集所属的数据库名称 db.test.getIndexes() 返回些数据集的索引信息 db.test.group(&#123;key:...,initial:...,reduce:...[,cond:...]&#125;) 返回分组信息 db.test.mapReduce(mayFunction,reduceFunction,&lt;optional params&gt;) 这个有点像存储过程 db.test.remove(query) 在数据集中删除一条数据 db.test.renameCollection(newName) 重命名些数据集名称 db.test.save(obj) 往数据集中插入一条数据 db.test.stats() 返回此数据集的状态 db.test.storageSize() 返回此数据集的存储大小 db.test.totalIndexSize() 返回此数据集的索引文件大小 db.test.totalSize() 返回些数据集的总大小 db.test.update(query,object[,upsert_bool]) 在此数据集中更新一条数据 db.test.validate() 验证此数据集 db.test.getShardVersion() 返回数据集共享版本号 连接1mongodb://&#123;user&#125;:&#123;password&#125;@&#123;ip&#125;:&#123;port&#125;/&#123;dbname&#125; 数据库导出导入 导出：mongoexport 1234567mongoexport -d dbname -c collectionname -o file --type json/csv -f field 参数说明： -d ：数据库名 -c ：collection名 -o ：输出的文件名 --type ： 输出的格式，默认为json -f ：输出的字段，如果-type为csv，则需要加上-f &quot;字段名&quot; 导入：mongoimport 123456789101112mongoimport -d dbname -c collectionname --file filename --headerline --type json/csv -f field 参数说明： -h [ --host ] arg mongo host to connect to ( &lt;set name&gt;/s1,s2 for sets) --port arg server port. Can also use --host hostname:port -u [ --username ] arg username -p [ --password ] arg password -d ：数据库名 -c ：collection名 --type ：导入的格式默认json -f ：导入的字段名 --headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段 --file ：要导入的文件 tips，下载远程文件 1scp &#123;用户名&#125;@&#123;ip&#125;:&#123;路径/文件&#125; &#123;本地路径&#125;","categories":[],"tags":[]},{"title":"Linux基础学习笔记(2)","slug":"Linux基础学习笔记(2)","date":"2018-01-07T10:30:15.000Z","updated":"2018-01-29T06:46:09.432Z","comments":true,"path":"2018/01/07/Linux基础学习笔记(2)/","link":"","permalink":"http://maizsss.github.io/2018/01/07/Linux基础学习笔记(2)/","excerpt":"","text":"WebServerApache基本 安装： yum install httpd 启动：service httpd start 停止：service httpd stop 看进程：ps -ef | grep httpd 网络统计：sudu netstat -anpl | grep ‘http’ 虚拟主机配置 12345678910111213// 编辑配置需要先提权vim /etc/httpd/conf/httpd.conf// 编写内容&lt;VirtualHost *:80&gt; ServerName &#123;域名&#125; DocumentRoot &#123;根路径&#125; &lt;Directory &quot;&#123;根路径&#125;&quot;&gt; Options Indexed FollowSymLinks AllowOverride none Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;// 保存重启 把某个文件为帐号提权：sudo chown -R {帐号}:{帐号} {目录} 开启宽松模式：sudo setenforce 0 or vim /etc/selinux/config 伪静态 模块配置文件目录：/etc/httpd/conf.modules.d/ 模块目录：/etc/httpd/modules/ 配置伪静态：1234567891011121314151617181920vim /etc/httpd/conf/httpd.conf// 把伪静态加载LoadModule rewrite_module modules/mod_rewrite.so// 修改虚拟主机内容&lt;VirtualHost *:80&gt; ServerName &#123;域名&#125; DocumentRoot &#123;根路径&#125; &lt;Directory &quot;&#123;根路径&#125;&quot;&gt; Options Indexed FollowSymLinks AllowOverride none Require all granted // 加入以下内容 &lt;IfModule mod_rewrite.c&gt; RewriteEngine On RewriteRule ^(.*).htmp$ index.html &lt;/IfModule&gt; &lt;/Directory&gt;&lt;/VirtualHost&gt;// 保存重启 Nginx安装12345// 搜索，yum源没有nginx源yum search nginx// 添加CentOS 7 Nginx yum资源库sudo rpm -Uvh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpmsudo yum install -y nginx 基本操作 安装：yum install nginx 启动：service nginx start 停止：service nginx stop 重载：service nginx reload(无缝重载) 先杀死再启动：service nginx restart虚拟主机 配置： 123456789vim /etc/nginx/conf.d/&#123;配置名&#125;.confserver &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm;&#125; 伪静态 1234567891011server &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; rewrite ^(.*)\\.htmp$ /index.html; &#125;&#125; 日志（搜索nignx log_format学习日志配置） 1234vim /etc/nginx/nginx.conflog_format &#123;日志格式名&#125; &#123;格式&#125;access_log &#123;日志路径&#125; &#123;日志格式名&#125;; 反向代理（用户请求到A机器的nginx，nginx再请求B、C机器服务，再返回给用户） 负载均衡（N台机器同时接受请求） 123456789101112131415161718upstream &#123;服务名称&#125; &#123; server &#123;ip&#125;:&#123;port&#125; weight=5; // 服务1 server &#123;ip&#125;:&#123;port&#125; weight=1; //服务2 // weight设置权重&#125;server &#123; listen 80; listen 9999; server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; proxy_set_header Host &#123;域名&#125;; proxy_pass http://&#123;服务名&#125;; &#125;&#125; 调试 1234567891011121314151617181920upstream &#123;服务名称&#125; &#123; server &#123;ip&#125;:&#123;port&#125; weight=5; // 服务1 server &#123;ip&#125;:&#123;port&#125; weight=1; //服务2 // weight设置权重&#125;server &#123; listen 80; listen 9999; add_header Content-Type &quot;text/plain chatset=utf-8&quot;; //设置header return 200 &quot;$http_host&quot;; // 直接返回给浏览器 server_name &#123;域名1&#125; &#123;域名2&#125;; root &#123;根路径&#125;; index index.html index.htm; location / &#123; proxy_set_header Host &#123;域名&#125;; proxy_pass http://&#123;服务名&#125;; &#125;&#125; 缓存服务memcached 安装：yum install memcached 启动：memcached -d -l -m -p 1234567// 查看网络服务netstat -anpl | grep memcached// 查看端口是否通,还能发送报文// 先安装yum install telnet.*telnet 127.0.0.1 11211// quit 退出 停止：kill {pid} redis 安装：源码编译安装 1234567891011121314// 下载wget http://download.redis.io/releases/redis-4.0.2.tar.gz// 解压tar xvfz redis-4.0.2.tar.gzcd redis-4.0.2// 查看安装说明cat INSTALLcat README.md// 编译// 需要先安装gccyum install gccmake MALLOC=libc// 安装make install 启动：./src/redis-server start/restart 停止：./src/redis-server top 客户端：./src/redis-client(cli)123set &#123;key&#125; &#123;value&#125;get &#123;key&#125;del &#123;key&#125; 123telnet &#123;host&#125; 6379// 需要先 CONFIG SET protected-mode no LPUSH 123456//pushLPUSH tmp_list item1LPUSH tmp_list item2LPUSH tmp_list item3//rangeLRANGE tmp_list 0 10 redis 菜鸟教程：http://www.runoob.com/redis/redis-commands.html 常用服务crontab 定时任务 配置任务：crontab -e 教程： https://www.cnblogs.com/intval/p/5763929.html Ntpdate 日期同步 安装： yum install ntpdate 同步时间：ntpdate cn.pool.ntp.org 改时区1234//删除原时区rm /etc/localtime// 设置东八区时区ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime Logrotate 日志切割 教程： https://linux.cn/article-4126-1.html supervisor 进程管理 教程：http://blog.csdn.net/xyang81/article/details/51555473 shell 简介 Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。 Shell 脚本 Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但读者朋友要知道，shell 和 shell script 是两个不同的概念。由于习惯的原因，简洁起见，本文出现的 “shell编程” 都是指 shell 脚本编程，不是指开发 shell 自身。 查看当前发行版可以使用的shell 12345cat /etc/shells // 输出/bin/sh/bin/bash/sbin/nologin 查看当前使用的shell 123echo $SHELL// 输出/bin/bash 教程：http://www.runoob.com/linux/linux-shell.html 别名 查看别名: alias 设置别名：alias {别名}=’{原命令}’ 永久生效：vi ~/.bashrc(写入环境变量配置文件) 12// 使配置生效source .bashrc 删除别名：unalias {别名} 常用快捷键 退出：ctrl+c 清屏：ctrl+l 光标移动到命令行首：ctrl+a 光标移动到行尾：ctrl+e 从光标所在位置删除到行首：ctrl+u 把命令放入后台：ctrl+z 在历史命令中搜索：ctrl+r","categories":[],"tags":[]},{"title":"Linux基础学习笔记(1)","slug":"Linux基础学习笔记(1)","date":"2018-01-07T08:02:25.000Z","updated":"2018-01-10T02:16:29.494Z","comments":true,"path":"2018/01/07/Linux基础学习笔记(1)/","link":"","permalink":"http://maizsss.github.io/2018/01/07/Linux基础学习笔记(1)/","excerpt":"","text":"安装虚拟机 虚拟机对于初上手Linux系统的人来说，是最经济的选择。能够省去买云服务器的费用，也能从Linux的安装开始学习Linux。在工作中也能从Windows或者Mac无缝切换到虚拟机环境。 virtual box下载 centos镜像 其他事项 虚拟机配置（用于开发）：redhat64位、1g内存、40g硬盘 点击虚拟机界面后，鼠标会独占，右ctrl能取消独占 设置windows与虚拟机之间的复制粘贴：设备-共享粘贴板-双向。（好像无效，还是用ssh吧。） mirrors.163.com是网易的镜像站，含有大量Linux镜像资源,免除国内访问国外资源很慢的烦恼。 准备工作 Minimal的镜像是最小系统镜像，不包含网络等其他软件，需要自己配置。 ifconfig（查看网络配置） yum install net-tools (安装该工具使ifconfig命令可用) ip addr（查看ip地址） vi /etc/sysconfig/network-scripts/ifcfg-xx xx在ip addr的2：{网卡名} 编辑ONBOOT=yes 命令： service network restart yum需要先替换默认源：步骤 内网ip换成局域网ip。虚拟机先关机，设置-网络-连接方式改成桥接。得到局域网ip可用于虚拟机ssh连接。 wget（yum install wget） mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup cd /etc/yum.repos.d/ wget http://mirrors.163.com/.help/CentOS7-Base-163.repo yum clean all; yum makecache SSH服务 SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。 安装 安装SSH yum install openssh-server 启动 service sshd start 设置开机运行 chkconfig sshd on linux平台安装SSH客户端 yum install openssh-clients(其实在安装openssh-server时已经顺便被安装好) 连接。 ssh {帐号}@{ip:端口(不填默认22)} -&gt; 输入密码 SSH config config是为了方便批量管理多个ssh config存放在 ~/.ssh/config config配置语法12345678910host &quot;&#123;名称1&#125;&quot; HostName &#123;ip&#125; User &#123;帐号&#125; Port &#123;端口&#125; host &quot;&#123;名称2&#125;&quot; HostName &#123;ip&#125; User &#123;帐号&#125; Port &#123;端口&#125;// 设置完就能以这种形式连接：ssh &#123;名称&#125; ssh免密登录： ssh key（使用非对称方式生成公钥和私钥）。私钥（~/.ssh）,公钥（~/.ssh/authorized_keys） linux生成ssh key： 1234cd ~/.sshssh-keygen输入名字输入密码（可空） 把.pub（公钥文件）内容放在~/.ssh/authorized_keys ssh-add ~/.ssh/imooc_rsa(linux需要) ssh安全端口（修改端口）123456vim /etc/ssh/sshd_config——————Port &#123;端口号1&#125;Port &#123;端口号2&#125;——————service sshd restart Linux常用命令软件操作命令 软件包管理器：yum 安装软件：yum install xxx 卸载软件：yum remove xxx 搜索软件：yum search xxx 清理缓存：yum clean packages 列出已安装：yum list 软件包信息：yum info xxx 硬件资源信息 内存：free -m 硬盘：df -h 负载：w或top load average： 0.00（最近1min） 0.01（最近5min） 0.05（最近10min） 等于1是满负荷 大于1超负荷 0.6~0.7是健康值 cpu个数和核数 cat /proc/cpuinfo cat是查看文件内容 文件操作命令 Linux文件目录结构 根目录: / 家目录：/home 临时目录: /tmp 配置目录: /etc 用户程序目录: /usr 文件基本操作命令 查看目录下的文件: ls（ls -al == ll 显示文件详细信息） 新建文件： touch 新建文件夹：mkdir（-p 表示循环生成） 进入目录： cd 删除文件和目录：rm（-r 表示循环删除， -rf 表示强制删除） 复制：cp 移动： mv 显示路径：pwd Vim 教程 i键进入insert模式 esc退出insert模式，然后:wq(保存退出)，:q(退出)，:w(保存) G（最后一行），gg（行首） dd(删除本行), u(恢复) yy（复制光标所在行），p（粘贴） 文件权限421 r=4(读) w=2(写) x=1(可执行) drwxr-xr-x d表示文件类型，755 文件搜索，查找，读取 从文件尾部读取：tail(-f) 从文件头部读取：head 读取整个文件：cat 分页读取：more(enter键往下继续读) 可控分页：less 搜索关键字：grep(-n显示行数 “{关键字}” {文件名}) 查找文件：find（如：find . -name “{文件名关键字}”，-type表示查找类型，-ctime表示更新过的时间、天） 统计个数：wc 管道：|（把上一次操作的结果传递给下一次操作，如：grep “{关键字}” {文件名}|wc -l，统计某文件里出现某关键字的行数） 文件压缩解压 man {命令}（查看一个命令的说明） 压缩、解压：tar1234567-cf &#123;文件名.tar&#125; &#123;文件名&#125;,创建一个压缩文件-tf,查看压缩文件内容-tvf,查看压缩文件详细内容-xf,解压文件-czvf &#123;文件名.tar.gz&#125; &#123;文件名&#125;,创建一个.gz压缩文件并查看-tzvf， 查看一个.gz压缩文件-xzvf,解压一个.gz压缩文件 系统用户命令 添加用户：useradd 123cd /homeuseradd &#123;用户名&#125;passwd &#123;用户名&#125; adduser（与useradd有何不同） 删除用户：userdel（-r，彻底删除） 设置密码：passwd 防火墙设置 安装：yum install firewalld 启动：service firewalld start 重启：service firewalld restart 检查状态：service firewalld status 关闭或禁用防火墙：service firewalld stop/disable firewall-cmd 移除服务：–remove-service=ssh 添加服务：–add-service=ssh 查询具体的某个服务：–query-service=ssh 列出服务：–list-services 查询端口：–query-port=22/tcp 添加端口：–add-port=22/tcp 列出端口：–list-ports 列出区域配置情况：–list-all-zones 提权和文件上传下载操作 提权 sudo12visudo增加行:%&#123;需要提权的帐号&#125; ALL=(ALL) ALL, 保存退出 文件下载 wget {链接} curl1curl -o &#123;文件名&#125; &#123;链接&#125; 文件上传 从本地上传到远端：scp {文件名} {用户名}@{ip}:{路径} 从远端下载到本地：scp {用户名}@{ip}:{路径/文件} {本地路径} xshell上传文件1234//远端需要安装一个软件yum install lrzszrz //弹出弹窗，选择文件就能实现上传sz &#123;文件名&#125; //下载","categories":[],"tags":[]},{"title":"Web性能优化","slug":"Web性能优化","date":"2017-12-12T03:17:22.000Z","updated":"2017-12-12T07:00:31.130Z","comments":true,"path":"2017/12/12/Web性能优化/","link":"","permalink":"http://maizsss.github.io/2017/12/12/Web性能优化/","excerpt":"","text":"这是早期总结下来的一些项目优化经验，现在整理成文。或者有些地方已经过时或是不准确，欢迎指出。 “web性能优化”是个系统化工程，数据、资源存储=&gt;网络传输=&gt;页面展示，系统架构、代码、资源，每个层面都有可深入优化的地方。网上关于这方面的文献也挺多，流传最多的可算是雅虎网站页面性能优化的34条黄金守则。然而只有能适合具体业务环境的、花费更小的成本实现更大优化的，才是有效的优化。下面我想结合自己平时所接触的业务，从身边能够着手操作的地方，抛砖引玉也说几点。 从“瘦身”这个件事说起 现在的个人电子设备配置已经很高了，硬件运行效率不再成为限制。web的主要性能瓶颈在于网络带宽。减少要传输的资源的体积，是web优化最重要的事情，没有之一。代码压缩 css压缩、js压缩，前端自动化工具如gulp、grunt已经提供了成熟的压缩技术方案。又如模块化打包工具webpack，提供了一系列“黑魔法”可以设置优化（optimization），不只是压缩，还能针对单页面、多页面应用优化方案来灵活设置。css只能去回车、空格、注释，压缩率不算太高，但js能混淆变量，压缩率能达到50%左右。 html压缩存在着争议。虽然也属于能减少体积的手段，然而在经过gzip压缩后，html本身是否有压缩体积区别不大。而且html压缩还会带来一些问题，如回车、空格后，在页面渲染时会有一个字符的间隙，压缩后因为回车被去除这个间隙也没有了，给开发造成不便。图片压缩 页面中图片占比最大，对图片进行压缩很有必要。在线压缩png的网站，特别推荐熊猫（有兴趣的同学可以研究一下TinyPNG的压缩算法），而腾讯的智图支持多种格式图片的压缩。gzip压缩 浏览器发送请求的时候，请求头会带上Accept-Encoding（浏览器告诉服务器自己支持什么编码）。 image gzip是主流浏览器普遍支持的压缩编码，而sdch是chrome推广的压缩编码。服务器知道后就返回对应的编码内容。而gzip能设置压缩比率，越高压缩率就越高但消耗cpu资源，压缩后能比原文件减少40%~80%的体积，压缩率非常可观。但gzip对媒体文件（图片、视频）的压缩效果不明显，所以一般只对css、js、html格式资源开启。 做好了资源“瘦身”之后，其实优化已进行了60%了，这是低成本换取大成效的优化，在平时开发中应该是必备手段。 从网络传输层入手 在浏览器输入一个地址，然后按下回车，就会一系列网络传输事情：域名解析、TCP三次握手，浏览器发起http请求，服务器响应，浏览器解析html代码，请求静态资源，浏览器渲染页面。浏览器本身对一些环节也内置了优化措施，如DNS缓存、本地资源缓存等，对其熟悉的开发者可以从当中环节入手进行优化。200 OK (from cache) 、304 Not Modified 这是浏览器使用缓存时的状态码，但区别是前者是浏览器没有对服务器发出真实的请求，后者是有向服务器确认过后再使用缓存。 12345678910// 请求头里包含了If-Modified-Since:Thu, 12 May 2016 01:39:48 GMTIf-None-Match:&quot;ALZ8LAH1tVxaNHjkdcovaHQok277&quot;//响应头里包含了ETag:&quot;ALZ8LAH1tVxaNHjkdcovaHQok277&quot;Last-Modified:Thu, 12 May 2016 01:39:48 GMT 两者一致时，代表服务器上的资源没修改过，浏览器可使用缓存。 响应头中包含了Cache-Control信息，表明了资源可缓存时间，请求的资源在此时间内，就会出现200 ok（from cache）的状态。但当用户刷新浏览器时，还是304状态，需要向服务器重新确认。 12Cache-Control:public, max-age=31536000 利用浏览器缓存，能有效减少请求、网络带宽的开销。 减少请求 每个请求经过的步骤复杂，携带的多余信息也多，减少请求能降低服务器压力，减少消耗在DNS解析的时间，减少带宽消耗。 页面中使用外联js或css时，先进行合并、压缩处理。 多个icon或者小图片的资源，可以制作成雪碧图（CSS Sprites）。 单个小图片使用内嵌资源来引入，如：，webpack通过设置url-loader可把少于一定体积的图片自动转换成base64。 若使用ajax请求页面信息，尽量把多个零碎的请求合并成单个请求。 避免在页面脚本中做重定向，这等于浪费了一轮请求。利用html5特性进行资源缓存 html5提供了appcache和localstorage，能方便对静态资源、数据进行缓存。appcache： 应用缓存，在首次加载完资源后，再次请求该资源时可以直接使用缓存。目前已在项目中大量使用。但本身还是有几个坑，比如修改资源后用户要2次载入页面才能看到最新内容。又如会自动把使用appcache的页面html缓存，所以在多页项目中不适合使用appcache。localstorage： 本地存储，以键值对的形式把数据存储在本地，主流浏览器给每个域提供5mb左右容量。适用的场景很多。例如： 可对更新不频繁的，但用户会多次浏览的数据进行缓存，减少重复请求。 能代替部分cookie的功能，如存储用户信息。 把静态资源（css/js）缓存进localstorage。这种做法能解决远程资源加载问题，而且当单一域下有多个单独的webapp要用同一套js、css时，都能从本地直接读取。但这种做法带来了其他问题，如版本维护、脚本安全性、脚本执行效率。具体还待实践。DNS 预解析缓存 例：浏览器会提前对href下的域名进行 DNS 解析并且缓存，而不会在需要请求资源再进行解析。在一些大站中，为了并发加载资源而采取多域名cdn策略，DNS预解析效果就明显了。多域名策略 http请求会把当前域的cookie默认带上，但cookie对于css、js、图片资源是用处很小的，那么这样就会造成带宽浪费了。把一些资源放在别的域上，可以让http请求头减重。 http协议限制了单个域名的并发下载数，把要加载的资源分布在多个域名下，能提高并发。CDN加速 内容分发网络，能让用户就近取得所需内容，提高响应速度、解决网络延迟问题。目前已有很多cdn服务商能提供优质服务。 网络传输层面的优化也是web优化的一个大头，但是其实现成本较高，如cdn服务就需要购买，利用html5缓存就可能要涉及到架构上的改动，与承担新技术带来的风险。TCP优化、集群等，我还没接触过，欢迎补充。 从代码层面优化 浏览器把所需的资源加载回来后，还需要进行解析源码、渲染页面。代码质量带来的影响会随着代码的规模越来越明显。我是一名前端开发者，所以只从前端代码说起。html css、js使用外联方式引入，css在head时候就引入，js在html内容末尾引入。这样的做法能是html体积减少，并能使浏览器更快的取得css渲染页面，避免了因为加载和解析js而造成页面堵塞。 减少标签嵌套深度。 尽量少使用iframe。css 合理使用选择器。浏览器是从右向左解析css的选择器的，如： .a-block p.b-block a, 浏览器会查找所有a元素，查找带有.b-block类的父元素，查找这些父元素具有p标签的元素， 再往上匹配是否带有.a-block类的父元素。相比之下，.a-block .b-block .link这样的效率会稍好。 减少选择器嵌套深度。用less、sass这种预处理器，很容易就造成嵌套太深的情况，嵌套5、6层的情况常有。嵌套太深，会增加浏览器匹配查找的次数，应该控制在3层以内。 给图片写定宽高，避免图片加载完成后，图片本身的宽高撑开页面内容，造成了部分页面重绘。js 小心操作DOM。DOM元素包含了数据、节点、事件等信息，是很重的，频繁操作的DOM的代价很高。比如： image 每次循环中就要执行一次DOM操作，document.getElementById(‘list’).getElementsByTagName(‘li’)，并获取其length值，在执行中还要操作一次DOM，改变其样式。改成以下会更优： image 首先就把获取到的DOM元素缓存，在for循环内先把DOM集合的length值缓存，在循环体内通过给DOM元素加上类的方式，实现改变样式的结果，而且还能应对有多个样式同时要改变的场景。避免了多次操作DOM。 使用documentFragment（文档片段）对页面大块内容的更改。每次文档插入都是一次开销，并可能是页面重绘，当有大块文档需要插入时，较优的做法是创建documentFragment对象，再对此对象进行复杂的操作，最后才一次性插入到文档。js库vuejs也采用了这种做法。 使用事件代理方式来给元素绑定事件绑定事件会占用处理时间与内存。利用事件冒泡机制，只在父元素上绑定事件，然后判断事件源，就能处理子元素的事件了。jquery等一些流行库已在绑定事件方法的底层封装好这种方式。 操作页面元素时，要尽量避免发生重绘。代码质量是个持续优化的过程，应该在开发意识中提升。 “用户感知”性能 web优化的最终目的是能让用户更快地看到页面内容。然而除了让页面更快地加载之外，还有其他方式能让用户更快看到页面内容。懒加载 以内容主导的站点很多采用了懒加载。当页面内容过多的时候，首次只加载用户能看到的第一屏的内容，当用户继续往下浏览时，再按需加载更多内容。这样无需把整个页面都加载完就能让用户更快地看到内容。使用的场景如图片、长列表、历史消息。预加载 漫画网站、小说网站中，用户在浏览当页中的内容过程中，下一页的内容已经在加载了，在用户点击下一页时，就能立刻看到内容。避免资源浪费 在移动端上，各种设备的屏幕大小不一，在小屏上使用一个大分率的图片没必要。其实在小屏设备上用更小分辨率的图片，在用户看来都是一样。可以通过js判断当前设备屏宽引入不同的图片url，或者css3的媒体查询也可实现。让“等待”更有趣 当请求需要的时间比较长时，提供一些交互元素让用户的等待更有趣，那么用户会原谅页面加载的慢，页面加载也会显得更流畅，尽管费时可能更多。详见知乎。 这部分就有点涉及用户体验方面的优化了，需要与设计、交互一起探讨方案。 最后提出的一点是，优化的时机要合适。项目开始前可以布置资源缓存优化的基础建设，前期还需要根据业务需求设计好交互、体验上的优化。项目进行中就应该进行代码级的优化，如果到了后期再回头优化代码就伤筋动骨了。项目发布前，就要进行资源压缩。高成本的优化要等项目上线一定时间后再视乎情况而进行，避免过早优化，花费大力气去优化一个不显眼的地方。","categories":[],"tags":[]},{"title":"前端错误监控平台的搭建","slug":"前端错误监控平台的搭建","date":"2017-12-06T10:25:10.000Z","updated":"2017-12-06T10:26:19.330Z","comments":true,"path":"2017/12/06/前端错误监控平台的搭建/","link":"","permalink":"http://maizsss.github.io/2017/12/06/前端错误监控平台的搭建/","excerpt":"","text":"前端错误监控系统的搭建前端错误监控是什么 把错误日志打点到系统，系统提供日志数据可视化便于分析与定位问题。也可以称为日志分析平台。 ELK是常用的日志分析平台，ELK是ElasticSearch、Logstash和Kiabana三个开源工具的简称，分别提供搜索、存储、可视化功能。具体可参考一篇文章:戳这里。 针对前端的监控有多种，“应用错误”、“代码级别错误”、“性能”、“用户行为”，这次主要从“代码级别错误”来展开讨论。 最小化的需求 image 监控系统如何实现 从需求上考虑，无必要搭建如ELK这样庞大的系统，有点杀鸡用牛刀的节奏。在一定应用群规模以内，可以把日志系统简单理解为一个能读写数据库的服务，加上其他辅助手段(定时任务、发消息套件)就能整合成一套可用、灵活、方便扩展的系统。 系统用前后分离的方式实现，罗列一下主要的技术。前端：vue、element-ui、echarts，服务端：nodejs7.6+koa2、db：mysql、orm: Sequelize、nodejs守护进程：pm2 系统架构图： image 选择从零开始搭建一套系统，另一方面也是为了自己实践一下服务端开发领域上面的技术。有了上述方案以后，掌握一定服务端技术的人其实已经能知道具体采用什么技术手段、如何去实现。我自己在实现功能过程中，也有过很多考虑，也踩过一些坑。 具体实现 业务端的埋点捕获不多说了，在这篇文章有较为详细的说明，延伸到其他技术栈也是同样的思路。 管理端 后台管理界面天然适合做成SPA，利用vue实现组件化开发，工作流上配合webpack进行一系列的工程化处理，可以十分快速地构建起一个前端应用。 UI框架上面，element-ui在之前的一些后台系统上面有过实践，这次为了图方便也选用了同样的。element-ui由国内饿了么团队开源，有vue、react版本，vue版本相对支持力度大，目前已经更新到2.0版本，而项目中用到的是1.4.X版本，这个版本官方维护到这年12月份。element-ui的文档友好，在github的issue回应也及时，UI组件能满足大多数业务常用需求。属于国内基于vue的UI组件库中较领先的。 另外值得一提的是在基于react的UI库中，由阿里开源的ant-design是个十分大而全的技术，UI设计上面也更简洁紧凑（提供了一套管理系统的设计规范），组件、功能更加丰富，提供一站式应用架构，可以短时间内就能把最小应用搭建起来。 在实现一些小规模的数据可视化需求中，国内echarts的出现频率很高，较大规模的需求可能就要选择highcharts，毕竟后者起步早，背后团队力量大，文档还详细易懂。两者都是以全配置的方式驱动，每种常用的图表官方或社区都有对应的例子参考。但如果有特殊需求就要花点时间翻阅长溜溜的配置文档。在配置驱动这个点上延伸想象，可以编写数据过滤器来实现图表的复用，快速消化基本的数据可视化需求。 服务端 为了能让系统能在短时间内运行起来，加上自己在服务端开发上涉足还浅，服务端选择的技术相对保守。市面上有整套的服务端解决方案，如eggjs、thinkjs，这类框架已经把service、日志、进程管理、定时任务、部署等都囊括了，最后并没有选用这些技术。npm庞大的生态，让我不需要担心功能的实现，每块领域都有优秀的npm包来解决。 Koa的使用需要理解中间件与context（上下文）的概念，但其实express也一样，只是koa对express而言是承接的关系，koa是面向未来的web框架。 Koa是一个轻量级的、极富表现力的http开发框架。一个web request会通过Koa的中间件栈，来动态完成response的处理。同时，Koa2采用了async和await的语法来增强中间件的表现力。Koa本身做的工作仅仅是定制了中间件的编写规范，而不内置任何中间件。 12345678910111213// 伪代码，捕获路由间抛出的错误日志。async function logger(ctx, next) &#123; try &#123; await next(); &#125; catch (error) &#123; //记录异常日志 console.error(moment().format(&apos;YYYY-MM-DD HH:mm:ss&apos;), &apos;, errorMsg:&apos;, JSON.stringify(formatLog(&#123;ctx, msg: error.toString()&#125;))); &#125;&#125; router.all( &apos;*&apos;, logger); pm2会把应用内的console输出作为日志，以上代码简单利用了这点做了简单的日志服务，另外配合定时任务按天分割日志、清除N天前的日志文件。pm2作为node的进程管理包是主流选择，它支持负载均衡（node cluster），0秒重载等，还能支持配置启动。 123456789101112131415161718192021222324apps : [ &#123; name : &apos;linghit_fe&apos;, script : &apos;bin/www&apos;, log_file : &quot;./logs/pm2-log.log&quot;, out_file : &quot;./logs/pm2-out.log&quot;, error_file : &quot;./logs/pm2-error.log&quot;, pid_file: &quot;./logs/pm2-linghit_fe.pid&quot;, merge_logs : true, log_date_format : &quot;YYYY-MM-DD HH:mm:SS&quot;, max_memory_restart: &quot;150M&quot;, instances : 2, exec_mode : &quot;cluster&quot;, env: &#123; COMMON_VARIABLE: &apos;true&apos; &#125;, env_production : &#123; NODE_ENV: &apos;production&apos; &#125;, env_development : &#123; NODE_ENV: &apos;development&apos; &#125; &#125;] pm2能以cluster的方式启动应用，充分发挥多核cpu的性能，本身是利用了node的cluster集群模块。在这个监控应用上，我开启了两个web进程（linghit_fe）,与其他的辅助进行，linghit_fe_logmaster用于管理日志，linghit_fe_task用于管理定时任务。再往深一点的主子进程控制，数据共享等还要继续学习深化。 image Sequelize作为一个mysql的orm包，能简化大量的数据库操作，通过定义model与数据表建立映射关系，在这之后的数据库操作都是方便、可靠的。Sequelize基于Promise实现异步流程控制，也能与async await很好配合使用。 1234567891011121314151617181920212223const modelA = sequelize.define(&apos;modelName&apos;, &#123; columnA: &#123; type: Sequelize.BOOLEAN, validate: &#123; is: [&quot;[a-z]&quot;,&apos;i&apos;], // will only allow letters max: 23, // only allow values &lt;= 23 isIn: &#123; args: [[&apos;en&apos;, &apos;zh&apos;]], msg: &quot;Must be English or Chinese&quot; &#125; &#125;, field: &apos;column_a&apos; // Other attributes here &#125;, columnB: Sequelize.STRING&#125;)sequelize.sync();await modelA.findAndCountAll(&#123; where: whereQuery, offset: per_page * (current - 1), limit: per_page, order: [[&apos;create_time&apos;, &apos;DESC&apos;]]&#125;); 报警机制，定时任务+方糖。 路由管理。引用了koa-router包，使用方式。在这套代码里我设计成集中管理的模式，集中在一处能看到整个应用的路由关系，避免随着业务扩展而逻辑凌乱路由分散。具体看码。 使用loadtest进行简单的压力测试，目前能稳定在每秒100请求下。到了120以上开始内存上涨，延时增加，但服务还没崩。150以上开始出现极大延时，大量请求超时，吞吐量下降。 12345678910111213141516171819var loadtest = require(&apos;loadtest&apos;);var options = &#123; url: url, method: &apos;GET&apos;, // maxRequests: 1000, requestsPerSecond: 100, concurrency: 20, statusCallback: function (error, result, latency) &#123; console.log(&apos;总请求量： %j,错误： %j，rps： %j，延时：%j ms &apos;, latency.totalRequests, latency.totalErrors, latency.rps, latency.meanLatencyMs); &#125;&#125;;loadtest.loadTest(options, function(error, result)&#123; if (error) &#123; return console.error(&apos;Got an error: %s&apos;, error); &#125; console.log(&apos;Tests run successfully&apos;);&#125;); 待扩展 统计数据的查询。根据传参判断，大于72小时的以小时为单位，其余以分钟为单位。查询语句上先以create_time（时间戳）用FROM_UNIXTIME格式化成对应的sqlFormat格式，在此基础上（date_format）分组查询做出统计。有没有更好的查询办法让统计粒度更自由？比如按10分钟，30分钟，天。 12345678910111213141516171819// 定义时段分割，小于1小时的以分钟为分割单位let timeSplit = (countQuery.create_time.$lt - countQuery.create_time.$gt) &gt;= (72 * 60 * 60) ? &#123; unit: 60 * 60, sqlFormat: &apos;%Y-%m-%e %H:00&apos;, momentFormat: &apos;YYYY-MM-D HH:00&apos;&#125; : &#123; unit: 60, sqlFormat: &apos;%Y-%m-%e %H:%i&apos;, momentFormat: &apos;YYYY-MM-D HH:mm&apos;&#125;;// 查询let queryCount = await db[modelName].count(&#123; where: countQuery, order: [&apos;create_time&apos;, &apos;ASC&apos;], attributes: [ [db.sequelize.fn(&apos;FROM_UNIXTIME&apos;, db.sequelize.col(&apos;create_time&apos;), timeSplit.sqlFormat), &apos;date_format&apos;] ], group: &apos;date_format&apos;&#125;); 用户模块、权限模块。在系统内部就可以管理不同项目接收报警信息的人，而不需要通过方糖扫码。 image APM模块。页面性能分析，浏览器分布分析。 页面巡航模块。利用UI自动化测试定时跑测试脚本，监控各个页面的实际情况。 大数据量的解决方案？目前定时(1个月)清理db。 防刷、防攻击手段？？？ nginx实现的多机集群均衡负载？？？（单机都还要省着用，还多机?） 1234upstream XXX.XXX.com &#123; server 123.456.789.111:7082; server 123.456.789.222:7082; &#125; 还有什么使用上面的优化？？","categories":[],"tags":[]},{"title":"vue项目的错误捕获方式","slug":"vue项目的错误捕获方式","date":"2017-11-01T04:16:28.000Z","updated":"2017-11-01T04:17:20.395Z","comments":true,"path":"2017/11/01/vue项目的错误捕获方式/","link":"","permalink":"http://maizsss.github.io/2017/11/01/vue项目的错误捕获方式/","excerpt":"","text":"为什么要捕获错误？ 为什么要花那么多的时间成本和精力去做什么捕获错误的事情？为什么要提高代码质量？为什么要让项目更健壮？这个问题我也不懂回答，不过这就好比”有得吃就行了，为什么要吃好，为什么要花大钱去吃什么米其林三星。” 目前为止我接触到的需要捕获错误的地方或目的有2： 做错误兼容，如： 1234var obj = &#123;&#125;;try &#123; obj = JSON.parse(json);&#125; catch(e) &#123;&#125; 做错误日志收集，帮助发现与定位问题。 已知的错误都在开发时处理掉了。需要捕获的是未知的错误： 未知的接口返回内容 未知的资源加载情况，如图片或其他媒体资源。 改了一处代码，没发现另一处被影响到的逻辑 较深层级的交互逻辑，没有在测试阶段被发现的问题 在MVVM时代，用window.onerror捕获错误已经不适用了 通常MVVM项目会有一个（或多个）入口html or js，假如我在入口处如此监听全局错误： 1234567891011121314151617&lt;body&gt; &lt;div id=&quot;container&quot;&gt; &lt;div id=&quot;app&quot;&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; window.onerror = function (msg, script, line, columns, error) &#123; console.log(msg); console.log(script); console.log(line); console.log(columns); &#125; &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://XXX.XXX.XXX/static/js/app.js&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/body&gt; 当入口js逻辑出现问题时,控制台出现报错信息 image 然而在onerror的错误捕获代码却输出 1234console.log(msg); //Script error.console.log(script); //&apos;&apos;console.log(line); //0console.log(columns); //0 这是什么鬼？以下是网络上的一些搜索结果 因为同源策略，Firefox, Chrome, Safari 等浏览器， 页面引用的非同域的外部脚本中抛出了异常，本页面无权限获得这个异常详情， 所以就成了 Script error.。 解决办法有：1.静态文件服务器设置 Access-Control-Allow-Origin 头信息。2.script 标签添加 crossorigin 属性。 似乎一切就明朗了吗？就能早点回家吃饭了吗？ 图样图森破啊~ 就算最后能按方法解决掉script跨域脚本的问题。也无法确实可行地捕获到vue代码里的错误。webpack合并压缩混淆过的代码，输出的报错信息可读性也是有限的。另外，在vue组件内的错误其实是已经被捕获过，不会再抛给全局的onerror。 vue是个先进的框架，它自己有便捷健全的错误监听机制。 捕获vue项目内全局错误 errorHandLer： 先读文档。具体用法： 1234567891011121314151617181920212223242526Vue.config.errorHandler = function (err, vm, info) &#123; let &#123; message, name, script, line, column, stack &#125; = err; // 在vue提供的error对象中，script、line、column目前是空的。但这些信息其实在错误栈信息里可以看到。 script = !_.isUndefined(script) ? script : &apos;&apos;; line = !_.isUndefined(line) ? line : 0; column = !_.isUndefined(column) ? line : 0; // 解析错误栈信息 let stackStr = stack ? stack.toString() : `$&#123;name&#125;:$&#123;message&#125;`; console.log(stackStr); /* ReferenceError: bbb is not defined at a.created (shortLink.vue:361) at It (vue.esm.js:2701) at a.t._init (vue.esm.js:4293) at new a (vue.esm.js:4463) at ee (vue.esm.js:3740) at init (vue.esm.js:3557) at u (vue.esm.js:5212) at l (vue.esm.js:5155) at a.t.nodeOps [as __patch__] (vue.esm.js:5697) at a.t._update (vue.esm.js:2460) */ // report code&#125; 错误信息已经很足够了。如果有错误上报系统，开发者根据上报的错误信息回归到具体的案发现场，配合webpack的sourceMap也能快速定位问题。 捕获vue组件错误 最近vue2.5发布，新增了一个errorCaptured钩子: 先看文档 errorCaptured所为一个vue组件的钩子函数，能捕获到子孙组件的错误。在错误信息的显示上面与errorHandler是一致的，在做错误收集时无必要重复。但errorCaptured的目的我估计更加集中于去做即时性的兼容处理，这与try catch的性质是相似的，但vue提供了一个组件层面可用的try catch。 特殊位置埋点捕获 比如说在收发请求时，有些问题并不会造成一个js的报错，然而前后端的交互也经常会因为协议上面的疏漏而造成问题。在项目中我用到了vue-resource这个http请求库。本身支持Promise API。那我可以这样做： 12345678910111213141516Vue.http.get(url).then((resp) =&gt; &#123; if (返回数据不符合正确的格式) &#123; throw `格式不正确`; &#125; if (typeof successFn === &apos;function&apos;) &#123; successFn(resp.body); //在处理回调函数内部出错时，也会被捕获到错误 &#125;&#125;, resp =&gt; &#123; throw `网络问题的错误`;&#125;).catch((err) =&gt; &#123; // 捕获到的错误信息会被包含在err对象里 // report code /* 在收集错误信息时，可以选择性地把调用的url、method、query、response数据一并上报，方便还原案发现场。 */&#125;); 是否便于埋点捕获还与项目的构成有关系，假如说项目里的请求都各走各路，那么处理逻辑就会很分散，开发者也会烦于维护。 出问题是无可避免的，问题的解决手段才是更重要，在问题大范围扩散前能发现问题，至少在代码上线后能淡定一点。","categories":[],"tags":[]},{"title":"前端的UI自动化测试","slug":"前端的UI自动化测试","date":"2017-10-28T07:14:09.000Z","updated":"2017-10-28T08:41:05.160Z","comments":true,"path":"2017/10/28/前端的UI自动化测试/","link":"","permalink":"http://maizsss.github.io/2017/10/28/前端的UI自动化测试/","excerpt":"","text":"0. 背景 单元测试：对构成程序的每个单元进行测试。工程上的一个共识是，如果程序的每个模块都是正确的、模块与模块的连接是正确的、那么程序基本上就会是正确的。以上是抄的，我也不懂。我的理解分两块，什么是单元？可以是函数、接口、组件、事务（what？）。什么是测试？就是验证功能，给予相同的输入（可以是数据、行为），会有相同的输出。 TDD（Test-Driven Development）：测试驱动开发。现写测试，后写业务，或者并行。对写测试的开发要求较高。 vue、react等组件化框架天生易于被测试，如element对alert组件测试的例子。理论上项目中的vue、react等组件都可以写测试，但前提是组件封装优良，模块间松耦合，对代码编写规范有要求。 下面要吹的是一套针对与UI测试的套件。 1. 相关工具 测试框架: Mocha（可以参考阮一峰的文章） 断言库: Chai 详情看文章介绍 测试工具: nightmare(git:https://github.com/segmentio/nightmare)。这是一个基于electron的自动化框架，相比起PhantomJS的语法更加简单。 2. 使用 全局安装mocha：npm install -g mocha 12345678# Linux &amp; Mac$ env ELECTRON_MIRROR=https://npm.taobao.org/mirrors/electron/ $ npm install# Windows$ set ELECTRON_MIRROR=https://npm.taobao.org/mirrors/electron/$ npm install 运行一个测试 1mocha ./testDemo/demo3.useChai.fn1.test.js 运行一系列测试 1mocha ./testDemo 3. nightmare的使用123456789101112131415161718192021const Nightmare = require('nightmare');const nightmare = Nightmare(&#123; show: true, //是否显示浏览器窗口 width: 1920, //浏览器窗口宽度 height: 1080 //浏览器窗口高度&#125;);nightmare .goto('http://www.linghit.com/') //打开一个url .wait('#generalize_content') //等待某个元素出现在dom .wait(2000) //等待2000ms .click('#closed') //点击某个dom .evaluate(function () &#123; //在浏览器环境下的操作 return window.location.href; &#125;) .end() //结束一个nightmare队列 .then((res) =&gt; &#123; //获取到evaluate的return值 console.log(res); &#125;) .catch((err) =&gt; &#123; //捕捉错误 console.log(err); &#125;) 4. mocha结合nightmare进行测试1234567891011121314151617181920212223242526272829303132333435'use strict';const expect = require('chai').expect;const Nightmare = require('nightmare');const nightmare = Nightmare(&#123; show: true, width: 1920, height: 1080&#125;);describe('灵机官网', function() &#123; // 用例超时时长 this.timeout(5 * 1000); it('页面是否能正常打开', (done) =&gt; &#123; nightmare .goto('http://www.linghit.com/') .wait('#generalize_content') .wait(1000) .click('#closed') .evaluate(function () &#123; var bannerLen = $('.banner').length; return &#123; bannerLen: bannerLen &#125;; &#125;) .end() .then((res) =&gt; &#123; expect(res.bannerLen).to.above(0); done(); &#125;) .catch((err) =&gt; &#123; done(err); &#125;) &#125;);&#125;); 5. 使用mochawesome生成测试报告1mocha .\\testDemo\\demo7.linghit.report.test.js --reporter mochawesome 6. 其他东西 nightmare的截屏 1.screenshot([path][, clip]) mocha的钩子函数 123456789101112131415before(function() &#123; // 在本区块的所有测试用例之前执行&#125;);after(function() &#123; // 在本区块的所有测试用例之后执行&#125;);beforeEach(function() &#123; // 在本区块的每个测试用例之前执行&#125;);afterEach(function() &#123; // 在本区块的每个测试用例之后执行&#125;); 通过node脚本定时巡航页面，并上报测试结果 1234567891011121314151617181920212223&lt;!-- index.js --&gt;setInterval(() =&gt; &#123; // 当然定时任务不会用setInterval。。。 shell.exec('mocha ./testDemo/demo8.other.test.js --reporter mochawesome', function(err) &#123; if( err ) &#123; throw err; &#125; else &#125; &#125;);&#125;, 10 * 1000);&lt;!-- 测试脚本 --&gt;after(async function() &#123; // 统一上报测试结果 var options = &#123; method: 'POST', url: 'http://localhost:3000/api/test/report', body: reportObj, //reportObj对象收集图片url，错误信息等等 json: true &#125;; var res = await request(options); &#125;);","categories":[],"tags":[]}]}